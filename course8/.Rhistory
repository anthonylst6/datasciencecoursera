set.seed(125)
model1 <- train(Class ~ ., method = "rpart", data = train)
library(rattle)
fancyRpartPlot(model1$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
str(olive)
model2 <- train(Area ~ ., method = "rpart", data = olive)
predict(model2, newdata = as.data.frame(t(colMeans(olive))))
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model3 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method = "glm", family = "binomial", data = trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, as.numeric(predict(model3, newdata = trainSA)))
missClass(testSA$chd, as.numeric(predict(model3, newdata = testSA)))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model1 <- train(y ~ ., method = "rf", data = vowel.train)
library(caret)
model1 <- train(y ~ ., method = "rf", data = vowel.train)
model2 <- train(y ~ ., method = "gbm", data = vowel.train)
model2 <- train(y ~ ., method = "gbm", data = vowel.train)
mean(predict(model1, subset(test, select = -c(y))) == test$y)
mean(predict(model1, subset(vowel.test, select = -c(y))) == vowel.test$y)
mean(predict(model1, vowel.test) == vowel.test$y)
model2 <- train(y ~ ., method = "gbm", data = vowel.train, verbose = FALSE)
mean(predict(model1, vowel.test) == vowel.test$y)
mean(predict(model2, vowel.test) == vowel.test$y)
mean((predict(model1, vowel.test) == vowel.test$y) & (predict(model2, vowel.test) == vowel.test$y))
mean(predict(model1, vowel.test) == vowel.test$y)
mean(predict(model2, vowel.test) == vowel.test$y)
mean(predict(model1, vowel.test) == vowel.test$y)
mean(predict(model2, vowel.test) == vowel.test$y)
mean(predict(model1, vowel.test) == vowel.test$y)
mean(predict(model2, vowel.test) == vowel.test$y)
str(vowel.train)
predict1 <- predict(model1, vowel.test)
predict2 <- predict(model2, vowel.test)
mean(predict1[predict1 == predict2] == vowel.test$y[predict1 == predict2])
set.seed(33833)
model1 <- train(y ~ ., method = "rf", data = vowel.train)
model2 <- train(y ~ ., method = "gbm", data = vowel.train, verbose = FALSE)
predict1 <- predict(model1, vowel.test)
predict2 <- predict(model2, vowel.test)
mean(predict1 == vowel.test$y)
mean(predict2 == vowel.test$y)
mean(predict1[predict1 == predict2] == vowel.test$y[predict1 == predict2])
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
set.seed(62433)
model3 <- train(diagnosis ~ ., method = "rf", data = training)
model4 <- train(diagnosis ~ ., method = "gbm", data = training, verbose = FALSE)
model5 <- train(diagnosis ~ ., method = "lda", data = training)
predict3 <- predict(model3, testing)
predict4 <- predict(model4, testing)
predict5 <- predict(model5, testing)
predDF <- data.frame(predict1, predict2, predict3, diagnosis = testing$diagnosis)
predDF <- data.frame(predict3, predict4, predict5, diagnosis = testing$diagnosis)
model6 <- train(diagnosis ~ ., method = "rf", data = predDF)
mean(predict3 == testing$diagnosis)
mean(predict4 == testing$diagnosis)
mean(predict5 == testing$diagnosis)
predict6 <- predict(model6, testing)
mean(predict6 == testing$diagnosis)
model6 <- train(diagnosis ~ ., method = "gam", data = predDF)
predict6 <- predict(model6, testing)
mean(predict6 == testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
str(concrete)
model7 <- train(CompressiveStrength ~ ., method = "lasso", data = training)
?plot.enet
plot.enet(model7, xvar = penalty)
plot(model7, xvar = penalty)
plot(model7, xvar = "penalty")
enet::plot(model7, xvar = "penalty")
elasticnet::plot(model7, xvar = "penalty")
plot(model7, xvar = "fraction")
plot(model7, xvar = "penalty")
plot(model7, xvar = "L1norm")
plot(model7, xvar = "step")
summary(model7)
summary(model7$finalModel)
View(model7)
coef(model7)
# Question 15a
data(boston)
# Question 15a
data(Boston)
# Question 15a
library(ISLR)
data(Boston)
# Question 15a
library(MASS)
data(Boston)
str(Boston)
lm.fit26 <- lm(crim ~ zn, data = Boston)
?Boston
lm.fit26 <- lm(crim ~ zn, data = Boston)
lm.fit27 <- lm(crim ~ indus, data = Boston)
lm.fit28 <- lm(crim ~ factor(chas), data = Boston)
lm.fit29 <- lm(crim ~ nox, data = Boston)
lm.fit30 <- lm(crim ~ rm, data = Boston)
lm.fit31 <- lm(crim ~ age, data = Boston)
lm.fit32 <- lm(crim ~ dis, data = Boston)
lm.fit33 <- lm(crim ~ rad, data = Boston)
lm.fit34 <- lm(crim ~ tax, data = Boston)
lm.fit35 <- lm(crim ~ ptratio, data = Boston)
lm.fit36 <- lm(crim ~ black, data = Boston)
lm.fit37 <- lm(crim ~ lstat, data = Boston)
lm.fit38 <- lm(crim ~ medv, data = Boston)
coef(lm.fit26)
lm.fit26$coef
summary(lm.fit26)$coef
summary(lm.fit26)$coef
summary(lm.fit27)$coef
summary(lm.fit28)$coef
summary(lm.fit29)$coef
summary(lm.fit30)$coef
summary(lm.fit31)$coef
summary(lm.fit32)$coef
summary(lm.fit33)$coef
summary(lm.fit34)$coef
summary(lm.fit35)$coef
summary(lm.fit36)$coef
summary(lm.fit37)$coef
summary(lm.fit38)$coef
# All predictors except chas are statistically significant under simple linear regression
plot(Boston$crim, Boston$chas)
# All predictors except chas are statistically significant under simple linear regression
plot(Boston$chas, Boston$crim)
# All predictors except chas are statistically significant under simple linear regression
plot(Boston$zn, Boston$crim)
plot(Boston$indus, Boston$crim)
plot(Boston$chas, Boston$crim)
plot(Boston$nox, Boston$crim)
# All predictors except chas are statistically significant under simple linear regression
pairs(Boston)
plot(Boston$age, Boston$crim)
plot(Boston$dis, Boston$crim)
plot(Boston$rad, Boston$crim)
plot(Boston$tax, Boston$crim)
plot(Boston$ptratio, Boston$crim)
plot(Boston$black, Boston$crim)
plot(Boston$lstat, Boston$crim)
plot(Boston$medv, Boston$crim)
plot(lm.fit26)
par(mfrow = c(2, 2))
plot(lm.fit26)
plot(lm.fit26)
plot(lm.fit27)
plot(lm.fit28)
plot(lm.fit29)
plot(lm.fit30)
plot(lm.fit31)
plot(lm.fit32)
plot(lm.fit33)
plot(lm.fit34)
plot(lm.fit35)
plot(lm.fit36)
plot(lm.fit37)
plot(lm.fit38)
plot(lm.fit28)
lm.fit39 <- lm(crim ~ ., data = Boston)
summary(lm.fit39)
cor(Boston)
vif(lm.fit39)
library(cars)
library(Cars)
library(car)
vif(lm.fit39)
plot(0.1, 0.2)
mfrow = c(2, 2)
par(mfrow = c(1, 1))
size(Boston)
dim(Boston)
col(Boston)
dim(Boston)
ncol(Boston)
paste0("lm.fit", 2 + 1)
coef(lm.fit26)
coef(lm.fit26)[2]
coef("lm.fit26")
coef(get("lm.fit26"))
coef(get("lm.fit26"))[2]
coef(lm.fit39)
coef(lm.fit39)[2]
for(i in 1:(ncol(Boston) - 1)) {
name <- paste0("lm.fit", 25 + i)
coefx <- coef(get(name))[2]
coefy <- coef(lm.fit39)[i + 1]
plot(coefx, coefy)
}
name <- paste0("lm.fit", 25 + i)
for(i in 1:(ncol(Boston) - 1)) {
name <- paste0("lm.fit", 25 + i)
coefx <- coef(get(name))[2]
coefy <- coef(lm.fit39)[i + 1]
points(coefx, coefy)
}
coords <- numeric(0)
coords <- data.frame(x = numeric(0), y = numeric(0))
for(i in 1:(ncol(Boston) - 1)) {
name <- paste0("lm.fit", 25 + i)
coords$x[i] <- coef(get(name))[2]
coords$y[i] <- coef(lm.fit39)[i + 1]
}
coords
name <- paste0("lm.fit", 26)
coords$x[1] <- coef(get(name))[2]
coords$x[1] <- 1
m <- numeric(0)
m[1] <- 2
coefx = numeric(0)
coefy = numeric(0)
for(i in 1:(ncol(Boston) - 1)) {
name <- paste0("lm.fit", 25 + i)
coefx[i] <- coef(get(name))[2]
coefy[i] <- coef(lm.fit39)[i + 1]
}
plot(coefx, coefy)
str(Boston)
names(Bosotn)
names(Boston)
# Question 15d
names <- names(Boston)
summary(lm.fit39)$coef
# Question 15d
names <- names(Boston)[4]
coef(lm.fit)
coef(lm.fit39)
summary(lm.fit39)$coef[4]
summary(lm.fit39)$coef[1, 4]
# Question 15d
for(i in 1:(length(names) - 1)) {
var <- names(Boston)[i + 1]
model <- lm(crim ~ poly(get(var), 3), data = Boston)
print(paste("Coefficients for", var))
print(summary(model)$coef[i + 1, 4])
print("----------------")
}
clear("name")
rm("name")
rm("names")
# Question 15d
for(i in 1:(length(names) - 1)) {
var <- names(Boston)[i + 1]
model <- lm(crim ~ poly(get(var), 3), data = Boston)
print(paste("Coefficients for", var))
print(summary(model)$coef[i + 1, 4])
print("----------------")
}
var <- names(Boston)[1 + 1]
var <- names(Boston)[2 + 1]
model <- lm(crim ~ poly(get(var), 3), data = Boston)
print(paste("p-value for", var))
# Question 15d
for(i in 1:(length(names) - 1)) {
var <- names(Boston)[i + 1]
model <- lm(crim ~ poly(get(var), 3), data = Boston)
print(paste("p-value for", var))
print(summary(model)$coef[i + 1, 4])
print("----------------")
}
var <- names(Boston)[1 + 1]
model <- lm(crim ~ poly(get(var), 3), data = Boston)
summary(model)
for(i in 1:(length(names) - 1)) {
var <- names(Boston)[i + 1]
model <- lm(crim ~ poly(get(var), 3), data = Boston)
summary(model)
}
model$coefficients
summary(model)
rm("var")
for(i in 1:(length(names) - 1)) {
var <- names(Boston)[i + 1]
model <- lm(crim ~ poly(get(var), 3), data = Boston)
summary(model)
}
names(Boston)
names(Boston)[1]
(length(names) - 1)
# Question 15d
for(i in 1:13) {
var <- names(Boston)[i + 1]
model <- lm(crim ~ poly(get(var), 3), data = Boston)
print(paste("p-value for", var))
print(summary(model)$coef[i + 1, 2:4])
print("----------------")
}
for(i in 1:13) {
var <- names(Boston)[i + 1]
model <- lm(crim ~ poly(get(var), 3), data = Boston)
summary(model)
}
# Question 15d
lm.zn = lm(crim~poly(zn,3))
summary(lm.zn)
str(Boston)
# Question 15d
lm.zn = lm(crim ~ poly(zn, 3))
# Question 15d
attach(Boston)
lm.zn = lm(crim ~ poly(zn, 3))
lm.indus = lm(crim ~ poly(indus, 3))
lm.chas = lm(crim ~ poly(chas, 3))
lm.nox = lm(crim ~ poly(nox, 3))
lm.rm = lm(crim ~ poly(rm, 3))
lm.age = lm(crim ~ poly(age, 3))
lm.dis = lm(crim ~ poly(dis, 3))
lm.rad = lm(crim ~ poly(rad, 3))
lm.tax = lm(crim ~ poly(tax, 3))
lm.ptratio = lm(crim ~ poly(ptratio, 3))
lm.black = lm(crim ~ poly(black, 3))
lm.lstat = lm(crim ~ poly(lstat, 3))
lm.medv = lm(crim ~ poly(medv, 3))
summary(lm.zn)
summary(lm.zn)
summary(lm.indus)
summary(lm.chas)
summary(lm.nox)
summary(lm.rm)
summary(lm.age)
summary(lm.dis)
summary(lm.rad)
summary(lm.tax)
summary(lm.ptratio)
summary(lm.black)
summary(lm.lstat)
summary(lm.medv)
RNGversion("3.0.0")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(caret)
model1 <- train(y ~ ., method = "rf", data = vowel.train)
model2 <- train(y ~ ., method = "gbm", data = vowel.train, verbose = FALSE)
predict1 <- predict(model1, vowel.test)
predict2 <- predict(model2, vowel.test)
mean(predict1 == vowel.test$y)
mean(predict2 == vowel.test$y)
mean(predict1[predict1 == predict2] == vowel.test$y[predict1 == predict2])
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?gbm
?train
set.seed(62433)
model3 <- train(diagnosis ~ ., method = "rf", data = training, trControl = trainControl(method = "cv"), number = 3)
model4 <- gbm(diagnosis ~ ., data = training)
?gbm
set.seed(62433)
model3 <- train(diagnosis ~ ., method = "rf", data = training)
#model3 <- train(diagnosis ~ ., method = "rf", data = training, trControl = trainControl(method = "cv"), number = 3)
#model4 <- gbm(diagnosis ~ ., data = training)
model4 <- train(diagnosis ~ ., method = "gbm", data = training, verbose = FALSE)
model5 <- train(diagnosis ~ ., method = "lda", data = training)
predict3 <- predict(model3, testing)
predict4 <- predict(model4, testing)
predict5 <- predict(model5, testing)
predDF <- data.frame(predict3, predict4, predict5, diagnosis = testing$diagnosis)
model6 <- train(diagnosis ~ ., method = "rf", data = predDF)
predict6 <- predict(model6, testing)
mean(predict3 == testing$diagnosis)
mean(predict4 == testing$diagnosis)
mean(predict5 == testing$diagnosis)
mean(predict6 == testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model7 <- train(CompressiveStrength ~ ., method = "lasso", data = training)
plot(model7$finalModel, xvar = "step")
plot(model7$finalModel, xvar = "step", use.color = T)
plot(model7$finalModel, xvar = "penalty", use.color = T)
setwd("C:/Users/user/Desktop/jhudatascience/course8")
if(!file.exists("data")) {
dir.create("data")
}
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
if(!file.exists("gaData.csv")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(fileURL, destfile = "gaData.csv")
}
library(lubridate) # For year() function below
dat = read.csv("./data/gaData.csv")
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?ts
?bats
install.packages("forecast")
library(forecast)
?bats
model8 <- bats(tstrain)
tstest <- ts(testing$visitsTumblr)
?ets
ets <- ets(tstrain, model = "MMM")
plot(decompose(tstrain),xlab="Years+1")
str(training)
str(testing)
ets <- ets(tstrain, model = "ZZZ")
fcast <- forecast(ets)
plot(fcast)
lines(tstest,col="red")
accuracy(fcast, tstest)
View(ets)
View(training)
View(testing)
?forecast
class(model8)
fcast <- forecast(tstest, model = model8)
accuracy(fcast, tstest)
fcast <- forecast(tstrain, model = model8)
accuracy(fcast, tstest)
summary(fcast)
summary(fcast)$lower
lower(fcast)
summary(fcast)$lower
summary(fcast)$Forecasts
fcast$lower
fcast$lower[2]
fcast$lower[, 2]
fcast <- forecast(tstrain, model = model8, h = 2)
summary(fcast)
fcast <- forecast(tstrain, model = model8, h = 235)
summary(fcast)
c(2, 1) > c(1, 1)
c(3, 1) > c(2, 1) > c(1, 1)
fcast$lower[, 2]
mean(testing$visitsTumblr > fcast$lower[, 2] & testing$visitsTumblr < fcast$upper[, 2])
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
?e1071
library(e1071)
?e1071
??e1071
?svm
model9 <- svm(CompressiveStrength ~ ., data = training)
set.seed(325)
model9 <- svm(CompressiveStrength ~ ., data = training)
rmse(testing$CompressiveStrength, predict(model9, newdata = testing))
set.seed(325)
model9 <- svm(CompressiveStrength ~ ., data = training)
RMSE <- function(y, yhat) sqrt(mean((y - yhat)^2))
set.seed(325)
model9 <- svm(CompressiveStrength ~ ., data = training)
RMSE(testing$CompressiveStrength, predict(model9, newdata = testing))
mean(predict3 == testing$diagnosis)
mean(predict4 == testing$diagnosis)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model3 <- train(diagnosis ~ ., method = "rf", data = training)
model4 <- train(diagnosis ~ ., method = "gbm", data = training, verbose = FALSE)
model5 <- train(diagnosis ~ ., method = "lda", data = training)
predict3 <- predict(model3, testing)
predict4 <- predict(model4, testing)
predict5 <- predict(model5, testing)
predDF <- data.frame(predict3, predict4, predict5, diagnosis = testing$diagnosis)
model6 <- train(diagnosis ~ ., method = "rf", data = predDF)
predict6 <- predict(model6, testing)
mean(predict3 == testing$diagnosis)
mean(predict4 == testing$diagnosis)
mean(predict5 == testing$diagnosis)
mean(predict6 == testing$diagnosis)
